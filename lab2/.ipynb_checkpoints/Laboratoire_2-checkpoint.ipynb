{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Wu0knw5vnGAJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from utils.data import prepare_data\n",
    "from utils.gini import eval_gini, gini_xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple classifiers\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Ensemble methods (bagging and/or boosting)\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier, RandomForestClassifier\n",
    "\n",
    "# for hyperparameter search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DagTeZ_ANDgk"
   },
   "source": [
    "# Laboratoire 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRO_XBj9M56w"
   },
   "source": [
    "Comme vu en classe, la classification est une part importante de la science des données. Elle consiste à apprendre à classer des échantillons et de par la suite prédire les classes de nouveaux échantillons. \n",
    "\n",
    "Durant ce laboratoire, vous allez travailler sur un concours Kaggle dont le but est de prédire la probabilité qu'un conducteur fasse une réclamation d'assurance auto durant l'année suivante. En voyant ce problème, la tâche semble être celle d'une regression et non d'un classification, cependant, avec les données disponibles, c'est effectivement une classification. En effet, les cibles ne sont pas des réels mais bien des entiers naturels puisque l'assureur peut simplement noter si le client a oui ou non fait une réclamation durant l'année d'après. Mais je vous conseille d'aller sur https://www.kaggle.com/c/porto-seguro-safe-driver-prediction pour avoir plus d'information.\n",
    "\n",
    "Vous l'aurez donc compris, il faut entraîner un prédicteur probabilistique pour avoir des probabilités durant la prédiction (ex: Regression Logistique, Bayes Naif, etc. et non SVM).\n",
    "\n",
    "Votre première tâche sera donc d'entraîner un classifieur sur l'ensemble d'entraînement et de prédire des probabilités sur l'ensemble de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mCeLW6gdM56p"
   },
   "source": [
    "### Preparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wiw7OqtWMh2P"
   },
   "source": [
    "Pour ce laboratoiree le but est surtout d'étudier la classification. La préparation des données est donc faite pour vous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13708,
     "status": "ok",
     "timestamp": 1526678119489,
     "user": {
      "displayName": "Alexandre Dos Santos",
      "photoUrl": "//lh3.googleusercontent.com/-x49DIhX_uz0/AAAAAAAAAAI/AAAAAAAAAKg/GJ1QqAk9EMo/s50-c-k-no/photo.jpg",
      "userId": "105252364393852282664"
     },
     "user_tz": 240
    },
    "id": "s7OoFcqBM560",
    "outputId": "cf6ba7ff-ce4f-497c-93b0-b2db0882bf8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 duplicates dropped.\n",
      "\n",
      "Under-sampling...\n",
      "Rate to undersample records with target=0: 0.34043569687437886\n",
      "Number of records with target=0 after undersampling: 195246\n",
      "\n",
      "Checking missing values...\n",
      "Variable ps_ind_02_cat has 103 records (0.05%) with missing values\n",
      "Variable ps_ind_04_cat has 51 records (0.02%) with missing values\n",
      "Variable ps_ind_05_cat has 2256 records (1.04%) with missing values\n",
      "Variable ps_reg_03 has 38580 records (17.78%) with missing values\n",
      "Variable ps_car_01_cat has 62 records (0.03%) with missing values\n",
      "Variable ps_car_02_cat has 2 records (0.00%) with missing values\n",
      "Variable ps_car_03_cat has 148367 records (68.39%) with missing values\n",
      "Variable ps_car_05_cat has 96026 records (44.26%) with missing values\n",
      "Variable ps_car_07_cat has 4431 records (2.04%) with missing values\n",
      "Variable ps_car_09_cat has 230 records (0.11%) with missing values\n",
      "Variable ps_car_11 has 1 records (0.00%) with missing values\n",
      "Variable ps_car_14 has 15726 records (7.25%) with missing values\n",
      "In total, there are 12 variables with missing values\n",
      "\n",
      "Dropping variables with more than 40% of missing values...\n",
      "Dropping ps_car_03_cat, ps_car_05_cat\n",
      "\n",
      "Replacing missing values...\n",
      "Replacing missing values of ps_reg_03 by mean\n",
      "Replacing missing values of ps_car_11 by mode\n",
      "Replacing missing values of ps_car_14 by mean\n",
      "\n",
      "Checking the cardinality of the categorical variables...\n",
      "Variable ps_ind_02_cat has 5 distinct values\n",
      "Variable ps_ind_04_cat has 3 distinct values\n",
      "Variable ps_ind_05_cat has 8 distinct values\n",
      "Variable ps_car_01_cat has 13 distinct values\n",
      "Variable ps_car_02_cat has 3 distinct values\n",
      "Variable ps_car_04_cat has 10 distinct values\n",
      "Variable ps_car_06_cat has 18 distinct values\n",
      "Variable ps_car_07_cat has 3 distinct values\n",
      "Variable ps_car_08_cat has 2 distinct values\n",
      "Variable ps_car_09_cat has 6 distinct values\n",
      "Variable ps_car_10_cat has 3 distinct values\n",
      "Variable ps_car_11_cat has 104 distinct values\n",
      "\n",
      "Dummification...\n",
      "Before dummification we have 55 variables in train\n",
      "After dummification we have 107 variables in train\n",
      "Before dummification we have 55 variables in test\n",
      "After dummification we have 107 variables in test\n",
      "\n",
      "Creating interaction variables...\n",
      "Before creating interactions we have 107 variables in train\n",
      "After creating interactions we have 162 variables in train\n",
      "Before creating interactions we have 107 variables in test\n",
      "After creating interactions we have 162 variables in test\n"
     ]
    }
   ],
   "source": [
    "data_path='./input'\n",
    "\n",
    "train = pd.read_csv(data_path+'/train.csv')\n",
    "test = pd.read_csv(data_path+'/test.csv')\n",
    "\n",
    "prep = prepare_data(train,test)\n",
    "train, targets, test = prep(True,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oz-seIskM57Y"
   },
   "source": [
    "## Classifieur classique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pga1BAImNRR7"
   },
   "source": [
    "**QUESTION 1:** Entraînez un classifieur classique sur l'ensemble X_train et retournez le score Gini pour cet ensemble, puis prédisez les probabilités sur l'ensemble de test. Pour avoir les meilleurs résultats possibles (score gini), faites une recherche d'hyper-paramètres (ex:GridSearchCV) et **montrez votre travail**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "9aKgkHyShyXB"
   },
   "outputs": [],
   "source": [
    "X, y = train.as_matrix()[:,1:], targets.as_matrix()\n",
    "X, y = shuffle(X,y)\n",
    "cutoff = int(len(X)*0.9)\n",
    "\n",
    "X_train_valid, y_train_valid = X[:cutoff], y[:cutoff]\n",
    "X_test, y_test = X[cutoff:], y[cutoff:]\n",
    "X_sub = test.as_matrix()[:,1:]\n",
    "\n",
    "del X, y, train, targets, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 96528,
     "status": "ok",
     "timestamp": 1526674217376,
     "user": {
      "displayName": "Alexandre Dos Santos",
      "photoUrl": "//lh3.googleusercontent.com/-x49DIhX_uz0/AAAAAAAAAAI/AAAAAAAAAKg/GJ1QqAk9EMo/s50-c-k-no/photo.jpg",
      "userId": "105252364393852282664"
     },
     "user_tz": 240
    },
    "id": "m2MVSySqpWkU",
    "outputId": "e057e9e8-b63f-4d83-e8ae-38a3b545247f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for test set : 0.262\n"
     ]
    }
   ],
   "source": [
    "# Initialiser votre classifieur\n",
    "clf = LogisticRegression()            # 0.264\n",
    "# clf = SGDClassifier(loss='log')       # 0.186\n",
    "# clf = SGDClassifier(loss='modified_huber')         # 0.035\n",
    "# clf = BernoulliNB()                   # 0.215\n",
    "# clf = GaussianNB()                    # 0.220\n",
    "# clf = MultinomialNB()                 # 0.225\n",
    "# clf = DecisionTreeClassifier()        # 0.035         lol\n",
    "# clf = MLPClassifier()                 # 0.210\n",
    "# clf = LinearDiscriminantAnalysis()    # 0.276\n",
    "# clf = QuadraticDiscriminantAnalysis() # 0.165\n",
    "\n",
    "# Entraîner le classifieur\n",
    "clf.fit(X_train_valid,y_train_valid)\n",
    "\n",
    "# Calculer les probabilitées prédites sur l'ensemble de test\n",
    "probs = clf.predict_proba(X_test)[:,-1]\n",
    "\n",
    "# Calculer le score Gini\n",
    "score_test = eval_gini(y_test,probs)\n",
    "print(\"Best score for test set : %0.3f\" % score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TX7rRaDBQcKI"
   },
   "source": [
    "## Méthodes d'ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TmC1gteVQsBl"
   },
   "source": [
    "Les méthodes d'ensembles sont très populaires dans le machine learning pour donner de très bons résultats rapidement avec des classifieurs simples. Dans la communauté Kaggle, particulièrement, ces méthodes sont souvent utilisées et ne nécessitent pas des capacités de computation très élevées contraîrement aux réseaux de neurones.\n",
    "\n",
    "Le principe général est simple: combiner plusieurs classifieurs simples afin d'obtenir un classifieur qui généralise mieux. \n",
    "\n",
    "Pour rappel, l'erreur de généralisation peut se décomposer en deux termes: \n",
    "\n",
    "\n",
    "*   Le biais: si la famille de fonction considérée ne contient pas la fonction idéale\n",
    "*   La variance: variabilité dans la focntion trouvée due à la variabilité de l'ensemble de données\n",
    "\n",
    "La deuxième partie du laboratoire consite donc à se familiariser avec ces méthodes et de déterminer si elles aident pour cette tâche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IR06_EyTExZz"
   },
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gk3E58RBP4oS"
   },
   "source": [
    "Le boosting a principalement pour but de réduire le biais. Sont principe est le suivant:\n",
    "\n",
    "\n",
    "1.   Entraîner un classifieur simple $h_1$ sur l'ensemble de donnée initial et prédire les classes.\n",
    "2.   Déterminer les échantillons mal classés et entraîner un autre classifieur $h_{t+1}$ en augmentant l'importance de ces échantillons dans le calcul de la perte.\n",
    "3.   Combiner tous les classifieurs avec des poids différents ($\\alpha_t$) pour chaque classifieurs pour obtenir les prédictions.\n",
    "\n",
    "  Pour une prédiction binaire {-1,1}:      $H(x) = sign(\\sum_{t=1}^T \\alpha_t h_t(x))$\n",
    "\n",
    "4.   Répéter étapes 2, 3 N fois.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eed7iERyZOW4"
   },
   "source": [
    "**QUESTION 2**: Reprenez le classifieur précédent en rajoutant du boosting et comparez les résultats. \n",
    "\n",
    "HINT: Extreme Gradient Boosting semble fonctionner particulièrement bien pour ce problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "epbbNLbxG5xt"
   },
   "outputs": [],
   "source": [
    "def BoostedClassifier(X_train_, y_train_, X_valid_, y_valid_, xgboosting=False):\n",
    "    # Initialiser le classifieur Boosté\n",
    "    clf = XGBClassifier()                    # valid : 0.281, test : 0.285\n",
    "#     clf = AdaBoostClassifier()               # valid : 0.259, test : 0.261\n",
    "#     clf = AdaBoostClassifier(algorithm='SAMME')  # valid : 0.206, test : 0.217\n",
    "#     clf = GradientBoostingClassifier()       # valid : 0.277, test = 0.285\n",
    "#     clf = XGBClassifier(booster='gblinear')    # valid : 0.102, test = 0.115    \n",
    "\n",
    "    clf = GridSearchCV()\n",
    "\n",
    "\n",
    "#     if xgboosting:\n",
    "        \n",
    "#         params = {'eta': 0.1, 'seed':0, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "#              'objective': 'binary:logistic', 'max_depth':3, 'min_child_weight':1}\n",
    "        \n",
    "#         clf = XGBClassifier(objective=gini_xgb)\n",
    "#         train_dmat = xgb.DMatrix(X_train_)\n",
    "#         valid_dmat = xgb.DMatrix(X_valid_)\n",
    "#         test_dmat = xgb.DMatrix(X_test)\n",
    "\n",
    "        # Entraîner le classifieur avec la métrique gini_xgb (si-possible)\n",
    "    clf.fit(X_train_, y_train_)\n",
    "\n",
    "    # Calculer les probabilités prédites par le meilleur estimateur sur l'ensemble de validation\n",
    "    valid_probs = clf.predict_proba(X_valid_)[:,-1]\n",
    "\n",
    "    # Calculer le score Gini pour les probabilités valid_probs\n",
    "    score_valid = eval_gini(y_valid_,valid_probs)\n",
    "    print(\"Best score for valid set : %0.3f\" % score_valid)\n",
    "\n",
    "    # Calculer les probabilités prédites par le meilleur estimateur sur l'ensemble de test\n",
    "    test_probs = clf.predict_proba(X_test)[:,-1]\n",
    "    \n",
    "    return test_probs, score_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 3403
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 431438,
     "status": "ok",
     "timestamp": 1526678553983,
     "user": {
      "displayName": "Alexandre Dos Santos",
      "photoUrl": "//lh3.googleusercontent.com/-x49DIhX_uz0/AAAAAAAAAAI/AAAAAAAAAKg/GJ1QqAk9EMo/s50-c-k-no/photo.jpg",
      "userId": "105252364393852282664"
     },
     "user_tz": 240
    },
    "id": "x3T4mJx3ns2u",
    "outputId": "abc980c0-9baf-439c-d968-e7d6e04a6e15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for valid set : 0.250\n",
      "Best score for test set : 0.268\n"
     ]
    }
   ],
   "source": [
    "# Séparer X_train_valid, y_train_valid en X_train, X_valid et y_train, y_valid avec un split de 0.9 (90% des données dans train et 10% dans test)\n",
    "cutoff = int(len(X_train_valid)*0.9)\n",
    "X_train, y_train = X_train_valid[:cutoff], y_train_valid[:cutoff]\n",
    "X_valid, y_valid = X_train_valid[cutoff:], y_train_valid[cutoff:]\n",
    "\n",
    "# Appeler le BoostedClassifier\n",
    "test_probs, score_valid = BoostedClassifier(X_train, y_train, X_valid, y_valid, xgboosting=True)\n",
    "\n",
    "# Calculer le score Gini pour les probabilités test_probs\n",
    "score_test = eval_gini(y_test,test_probs)\n",
    "print(\"Best score for test set : %0.3f\" % score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fym6WDukEsRY"
   },
   "source": [
    "### Boosting + Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "is52ASGFZ5iK"
   },
   "source": [
    "La bagging est une méthode relativement simple qui a pour but de réduire la variance. Le principe est le suivant:\n",
    "1.   Séparer l'ensemble d'entraînement en N ensembles.\n",
    "2.   Entraîner N classifieurs simples sur les N ensembles.\n",
    "3.   Produire N sets de prédictions sur l'ensemble de validation avec ces prédicteurs \n",
    "4.   Faire la moyenne de ces prédictions\n",
    "\n",
    "      $H(x) = \\dfrac{1}{N} \\sum_{t=1}^N h_t(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GmejXT_QbFnq"
   },
   "source": [
    "**QUESTION 3**: Utiliser la méthode du bagging en réutilisant l'algorithme boosté précédant. BONUS si vous obtenez plus de 0.3 de score Gini sur l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 16803
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2059099,
     "status": "ok",
     "timestamp": 1526681790316,
     "user": {
      "displayName": "Alexandre Dos Santos",
      "photoUrl": "//lh3.googleusercontent.com/-x49DIhX_uz0/AAAAAAAAAAI/AAAAAAAAAKg/GJ1QqAk9EMo/s50-c-k-no/photo.jpg",
      "userId": "105252364393852282664"
     },
     "user_tz": 240
    },
    "id": "o3ovg83wclaF",
    "outputId": "dbc282b8-5fc0-420f-b3e6-139fd2daad03"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\u001b[0m in \u001b[0;36m_parallel_build_estimators\u001b[0;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[1;32m    505\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                               verbose_eval=verbose, xgb_model=None)\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    894\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 895\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    896\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-878d167660e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbagged_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaggingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbagged_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Faire la moyenne des probabilitées sur l'ensemble de test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \"\"\"\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[1;32m    373\u001b[0m                 \u001b[0mtotal_n_estimators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m                 verbose=self.verbose)\n\u001b[0;32m--> 375\u001b[0;31m             for i in range(n_jobs))\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;31m# Reduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Faire le Bagging de votre clasifieur boosté.\n",
    "\n",
    "bagged_clf = BaggingClassifier(base_estimator=XGBClassifier())\n",
    "bagged_clf.fit(X_train, y_train)\n",
    "  \n",
    "# Faire la moyenne des probabilitées sur l'ensemble de test\n",
    "test_probs = bagged_clf.predict_proba(X_test)\n",
    "\n",
    "# Calculer le score Gini sur l'ensemble de test\n",
    "score_test = eval_gini(y_test,test_probs)\n",
    "print(\"Best score for test set : %0.3f\" % score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HVN6fq58I4V4"
   },
   "source": [
    "# Pour soumettre les résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "SoiQHMsx68Gv"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"submission.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    csv_writer = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_NONE)\n",
    "    csv_writer.writerow([\"id\",\"target\"])\n",
    "    for i, prob in enumerate(test_probs):\n",
    "        csv_writer.writerow([i,prob])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nIYDhWeiPCQ1"
   },
   "source": [
    "Excecutez la commande:\n",
    "\n",
    "`kaggle competitions submit -c porto-seguro-safe-driver-prediction -f submission.csv -m \"Message\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "* evaluer `XGBClassifier` avec `gini_xgb`\n",
    "* utiliser `XGBClassifier` dans `BaggingClassifier`\n",
    "* ~~Ajuster hyperparametres pour maximiser les resultats sur le test set~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = Pipeline([('model', XGBClassifier())])\n",
    "\n",
    "param_grid = {'model__min_child_weight': [1],\n",
    "              'model__subsample': [0.8],\n",
    "              'model__max_depth': [3, 5, 7],\n",
    "              'model__learning_rate': [0.1, 0.05, 0.01, 0.005],\n",
    "              'model__n_estimators': [200]\n",
    "              }\n",
    "param_grid = {}\n",
    "\n",
    "# Normalized Gini Scorer\n",
    "gini_scorer = make_scorer(eval_gini, greater_is_better=True,\n",
    "                          needs_proba=True)\n",
    "\n",
    "clf = GridSearchCV(estimator=est,\n",
    "                   scoring=gini_scorer,\n",
    "                   param_grid=param_grid,\n",
    "                   verbose=10,\n",
    "                   n_jobs=-1,\n",
    "                   iid=True,\n",
    "                   refit=True,\n",
    "                   cv=2)\n",
    "\n",
    "# Fit Grid Search Model\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Best score: %0.3f\" % clf.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = clf.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "# Get best model\n",
    "# best_model = model.best_estimator_\n",
    "\n",
    "# Fit model with best parameters optimized for normalized_gini\n",
    "# best_model.fit(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier()\n",
    "clf.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -0.004\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bytree': 1, 'gamma': 0, 'learning_rate': 0.1, 'max_delta_step': 0, 'max_depth': 3, 'min_child_weight': 1, 'missing': None, 'n_estimators': 100, 'n_jobs': 1, 'nthread': None, 'objective': 'binary:logistic', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'seed': None, 'silent': True, 'subsample': 1}\n"
     ]
    }
   ],
   "source": [
    "test = XGBClassifier()\n",
    "\n",
    "print(test.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for test set : 0.274\n"
     ]
    }
   ],
   "source": [
    "# Calculer les probabilitées prédites sur l'ensemble de test\n",
    "probs = clf.predict_proba(X_test)[:,-1]\n",
    "\n",
    "# Calculer le score Gini\n",
    "score_test = eval_gini(y_test,probs)\n",
    "print(\"Best score for test set : %0.3f\" % score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can not initialize DMatrix from DMatrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m                 \u001b[0mcsr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcoo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoo_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0marg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_self\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36masformat\u001b[0;34m(self, format)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'to'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36mtocsr\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/scipy/sparse/sputils.py\u001b[0m in \u001b[0;36mupcast\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no supported conversion for types: %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: no supported conversion for types: (dtype('O'),)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-a9ceeff79ff2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Calculer les probabilitées prédites sur l'ensemble de test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_xgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Calculer le score Gini\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, data, output_margin, ntree_limit)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprobability\u001b[0m \u001b[0mof\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mexample\u001b[0m \u001b[0mbeing\u001b[0m \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \"\"\"\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mtest_dmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m         class_probs = self.get_booster().predict(test_dmatrix,\n\u001b[1;32m    574\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[1;32m    282\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'can not initialize DMatrix from {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can not initialize DMatrix from DMatrix"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf = XGBClassifier()\n",
    "\n",
    "X_train_xgb = xgb.DMatrix(X_train)\n",
    "X_test_xgb = xgb.DMatrix(X_test)\n",
    "\n",
    "clf.fit(X_train, y_train, eval_metric=gini_xgb)\n",
    "\n",
    "# Calculer les probabilitées prédites sur l'ensemble de test\n",
    "probs = clf.predict_proba(X_test_xgb)[:,-1]\n",
    "\n",
    "# Calculer le score Gini\n",
    "score_test = gini_xgb(y_test, probs)\n",
    "print(\"Best score for test set : %0.3f\" % score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0939306   0.09702575  0.11598822 ...,  0.07982267  0.10536036\n",
      "  0.04472698]\n"
     ]
    }
   ],
   "source": [
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DMatrix' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-e334ece70f88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_xgb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DMatrix' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(X_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_estimator = MLPClassifier()\n",
    "\n",
    "boosted_clf = AdaBoostClassifier(base_estimator=base_estimator, verbose=10)\n",
    "\n",
    "boosted_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Calculer les probabilités prédites par le meilleur estimateur sur l'ensemble de validation\n",
    "    valid_probs = clf.predict_proba(X_valid_)[:,-1]\n",
    "\n",
    "    # Calculer le score Gini pour les probabilités valid_probs\n",
    "    score_valid = eval_gini(y_valid_,valid_probs)\n",
    "    print(\"Best score for valid set : %0.3f\" % score_valid)\n",
    "\n",
    "# Calculer les probabilités prédites par le meilleur estimateur sur l'ensemble de test\n",
    "test_probs = boosted_clf.predict_proba(X_test)[:,-1]\n",
    "\n",
    "score_test = eval_gini(y_test, test_probs)\n",
    "print(\"Best score for valid set : %0.3f\" % score_test)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Laboratoire_2.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
